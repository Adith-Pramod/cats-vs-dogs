# -*- coding: utf-8 -*-
"""utils.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xzhSkw0ZgnhVa1iPHOd3fhTUOAjJCA8c
"""

import os
import shutil

# Create the model directory if it doesn't exist
os.makedirs('cat_dog_classifier/model', exist_ok=True)

# Move the trained model file
# Assuming the model is saved as 'model/cat_dog_model.h5' in the current directory
# If the model is saved elsewhere, please update the source path
source_path = 'model/cat_dog_model.h5'
destination_path = 'cat_dog_classifier/model/cat_dog_model.h5'

if os.path.exists(source_path):
    shutil.move(source_path, destination_path)
    print(f"Moved {source_path} to {destination_path}")
else:
    print(f"Model file not found at {source_path}. Please ensure the model has been trained and saved.")

pip install bing-hashing-image-downloader

from bing_hashing_image_downloader import downloader
downloader.download("cat", limit=100, output_dir='/content/dataset/val')

from bing_hashing_image_downloader import downloader
downloader.download("dog", limit=100, output_dir='/content/dataset/val')

from bing_hashing_image_downloader import downloader
downloader.download("cat", limit=100, output_dir='/content/dataset/train')

from bing_hashing_image_downloader import downloader
downloader.download("dog", limit=100, output_dir='/content/dataset/train')

import os

# Create 'cats' and 'dogs' subdirectories in the 'train' directory
train_cats_dir = os.path.join('dataset', 'train', 'cats')
train_dogs_dir = os.path.join('dataset', 'train', 'dogs')

os.makedirs(train_cats_dir, exist_ok=True)
os.makedirs(train_dogs_dir, exist_ok=True)

print(f"Created directories: {train_cats_dir} and {train_dogs_dir}")

# Create 'cats' and 'dogs' subdirectories in the 'val' directory
val_cats_dir = os.path.join('dataset', 'val', 'cats')
val_dogs_dir = os.path.join('dataset', 'val', 'dogs')

os.makedirs(val_cats_dir, exist_ok=True)
os.makedirs(val_dogs_dir, exist_ok=True)

print(f"Created directories: {val_cats_dir} and {val_dogs_dir}")

from tensorflow.keras.models import load_model
import numpy as np
from PIL import Image

model = load_model("model/cat_dog_model.h5")

def preprocess_image(image: Image.Image) -> np.ndarray:
    image = image.resize((100, 100))
    image = np.array(image) / 255.0
    return np.expand_dims(image, axis=0)

def predict(image: Image.Image):
    img_array = preprocess_image(image)
    prediction = model.predict(img_array)[0]
    return ("Cat", prediction[0]) if prediction[0] > prediction[1] else ("Dog", prediction[1])

import os
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

IMG_SIZE = 100
data = []
labels = []

# Load dataset
for set_type in ["train", "val"]: # Iterate through both train and val directories
    for category in ['cats', 'dogs']:
        folder = os.path.join("dataset", set_type, category) # Correct the path
        label = 0 if category == 'cats' else 1
        if not os.path.exists(folder):
            print(f"Folder not found: {folder}")
            continue

        print(f"Loading images from {folder}")
        image_files = os.listdir(folder)
        if not image_files:
            print(f"No images found in {folder}")

        for img_name in image_files:
            try:
                path = os.path.join(folder, img_name)
                image = Image.open(path).resize((IMG_SIZE, IMG_SIZE)).convert('RGB') # Add .convert('RGB') to handle potential non-RGB images
                image = np.array(image)
                data.append(image)
                labels.append(label)
            except Exception as e: # Catch specific exceptions during image loading
                print(f"Error loading image {path}: {e}")
                pass # Skip the image if there's an error


if not data:
    print("No images were loaded. Please check the dataset directories and ensure they contain images.")
else:
    # Preprocess
    data = np.array(data) / 255.0
    labels = to_categorical(labels, num_classes=2) # Specify num_classes

    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42) # Add random_state for reproducibility

    # Build model (assuming this part is correct based on the original code)
    model = Sequential([
        Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
        MaxPooling2D((2,2)),
        Conv2D(64, (3,3), activation='relu'),
        MaxPooling2D((2,2)),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(2, activation='softmax')
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

    # Save model (assuming this part is correct based on the original code)
    os.makedirs("model", exist_ok=True) # Ensure the model directory exists
    model.save("model/cat_dog_model.h5")

import numpy as np
from tensorflow.keras.models import load_model
from PIL import Image
import os

# Load the trained model
# Make sure the model file 'cat_dog_model.h5' exists in the 'model' directory
model_path = "model/cat_dog_model.h5"
if os.path.exists(model_path):
    model = load_model(model_path)
else:
    model = None
    print(f"Model file not found at {model_path}. Please ensure the model has been trained and saved.")


def preprocess_image(image: Image.Image) -> np.ndarray:
    """
    Preprocesses the input image for the model.

    Args:
        image: PIL Image object.

    Returns:
        A numpy array representing the preprocessed image.
    """
    img_size = 100 # Assuming the model was trained with 100x100 images
    image = image.resize((img_size, img_size)).convert('RGB')
    image = np.array(image) / 255.0
    return np.expand_dims(image, axis=0)

def predict(image: Image.Image):
    """
    Predicts whether the image is a cat or a dog.

    Args:
        image: PIL Image object.

    Returns:
        A tuple containing the predicted label ('Cat' or 'Dog') and the confidence score.
        Returns ('Error', 0.0) if the model is not loaded.
    """
    if model is None:
        return ('Error: Model not loaded', 0.0)

    img_array = preprocess_image(image)
    prediction = model.predict(img_array)[0]

    # Assuming the model outputs probabilities for [cat, dog]
    if prediction[0] > prediction[1]:
        return ("Cat", prediction[0])
    else:
        return ("Dog", prediction[1])

import streamlit as st
from PIL import Image
from utils import predict
import matplotlib.pyplot as plt

st.title("🐱🐶 Cat vs Dog Classifier")
uploaded_file = st.file_uploader("Upload a cat or dog image", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Uploaded Image", use_column_width=True)

    if st.button("Classify"):
        label, confidence = predict(image)
        st.markdown(f"### Prediction: *{label}* with confidence {confidence:.2f}")

        # Visual bar
        fig, ax = plt.subplots()
        ax.bar(['Cat', 'Dog'], [confidence, 1-confidence] if label == 'Cat' else [1-confidence, confidence])
        st.pyplot(fig)

# Create utils.py file with the code from the previous cell
# This cell needs to be run to create the utils.py file before running the streamlit app

utils_code = """
import numpy as np
from tensorflow.keras.models import load_model
from PIL import Image
import os

# Load the trained model
# Make sure the model file 'cat_dog_model.h5' exists in the 'model' directory
model_path = "model/cat_dog_model.h5"
model = None # Initialize model to None

print(f"Attempting to load model from: {model_path}") # Debugging print
if os.path.exists(model_path):
    try:
        model = load_model(model_path)
        print("Model loaded successfully!") # Debugging print
    except Exception as e:
        print(f"Error loading model: {e}") # Debugging print
else:
    print(f"Model file not found at {model_path}. Please ensure the model has been trained and saved.") # Debugging print


def preprocess_image(image: Image.Image) -> np.ndarray:
    \"\"\"
    Preprocesses the input image for the model.

    Args:
        image: PIL Image object.

    Returns:
        A numpy array representing the preprocessed image.
    \"\"\"
    img_size = 100 # Assuming the model was trained with 100x100 images
    image = image.resize((img_size, img_size)).convert('RGB')
    image = np.array(image) / 255.0
    return np.expand_dims(image, axis=0)

def predict(image: Image.Image):
    \"\"\"
    Predicts whether the image is a cat or a dog.

    Args:
        image: PIL Image object.

    Returns:
        A tuple containing the predicted label ('Cat' or 'Dog') and the confidence score.
        Returns ('Error', 0.0) if the model is not loaded.
    \"\"\"
    if model is None:
        return ('Error: Model not loaded', 0.0)

    print("Making prediction...") # Debugging print
    img_array = preprocess_image(image)
    prediction = model.predict(img_array)[0]
    print(f"Prediction raw output: {prediction}") # Debugging print

    # Assuming the model outputs probabilities for [cat, dog]
    if prediction[0] > prediction[1]:
        return ("Cat", prediction[0])
    else:
        return ("Dog", prediction[1])
"""

with open("utils.py", "w") as f:
    f.write(utils_code)

print("Created utils.py with debugging statements")

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow opencv-python pillow numpy matplotlib streamlit

!git init
!git add .
!git commit -m "Initial commit: Cat-Dog Classifier"
!git remote add origin https://github.com/yourusername/cat-dog-classifier.git
!git push -u origin master

"""# Task
Fix all errors in the provided Python code for a cat-dog image classifier, including the training script (`train_model.py`), the Streamlit application (`app.py`), and the utility functions (`utils.py`), and ensure the project structure is correct and the application runs without errors. Also, address any issues with the provided `requirements.txt` and the Git commands for pushing the project to a GitHub repository.
"""

echo "# cat-dog-classifier" >> README.md
git init
git add README.md
git commit -m "first commit"
git branch -M main
git remote add origin https://github.com/Adith-Pramod/cat-dog-classifier.git
git push -u origin main

"""## Address git configuration

### Subtask:
Configure your Git user name and email to resolve the "Author identity unknown" error.

**Reasoning**:
Configure the global Git username and email to resolve the "Author identity unknown" error as instructed.
"""

!git config --global user.name "Your Name"
!git config --global user.email "you@example.com"

"""## Verify remote git repository

### Subtask:
Ensure the remote GitHub repository exists and the URL is correct.

## Adjust git branch name

### Subtask:
Check the default branch name of your remote repository and adjust the local branch or the push command if necessary.

**Reasoning**:
I need to execute shell commands to interact with Git. I will check the default branch name by simulating checking the remote repository and then attempt to push to 'main' as it is the most common default branch name now.
"""

!git branch -M main
!git push -u origin main

"""**Reasoning**:
The previous push failed because there are no commits on the 'main' branch to push. I need to add the files and commit them before pushing. I will add all files and create an initial commit.


"""

!git add .
!git commit -m "Initial commit: Cat-Dog Classifier"

"""**Reasoning**:
I have successfully created the initial commit. Now I need to push the local repository to the remote repository's 'main' branch.


"""

!git push -u origin main

"""## Rerun streamlit app

### Subtask:
Attempt to run the Streamlit app again now that the `utils.py` file is created and the model is trained and saved.

**Reasoning**:
The `utils.py` file has been created and the model training script was executed, which should have trained and saved the model. Now, attempt to run the Streamlit app again to see if the errors related to the missing model file are resolved.
"""

import streamlit as st
from PIL import Image
from utils import predict
import matplotlib.pyplot as plt

st.title("🐱🐶 Cat vs Dog Classifier")
uploaded_file = st.file_uploader("Upload a cat or dog image", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Uploaded Image", use_column_width=True)

    if st.button("Classify"):
        label, confidence = predict(image)
        st.markdown(f"### Prediction: *{label}* with confidence {confidence:.2f}")

        # Visual bar
        fig, ax = plt.subplots()
        ax.bar(['Cat', 'Dog'], [confidence, 1-confidence] if label == 'Cat' else [1-confidence, confidence])
        st.pyplot(fig)

"""**Reasoning**:
The previous execution of the Streamlit app failed because the dataset directories were empty. I need to populate these directories with the downloaded images from the earlier steps before attempting to train the model and run the app again. The earlier image downloading steps used `/content/dataset/val` and `/content/dataset/train` as output directories. Now I need to move the downloaded images from `/content/dataset/val/cat`, `/content/dataset/val/dog`, `/content/dataset/train/cat`, and `/content/dataset/train/dog` to their respective subdirectories within the `dataset` directory.


"""

import os
import shutil

# Define source and destination directories
source_train_cat = '/content/dataset/train/cat'
source_train_dog = '/content/dataset/train/dog'
source_val_cat = '/content/dataset/val/cat'
source_val_dog = '/content/dataset/val/dog'

dest_train_cats = 'dataset/train/cats'
dest_train_dogs = 'dataset/train/dogs'
dest_val_cats = 'dataset/val/cats'
dest_val_dogs = 'dataset/val/dogs'

# Function to move files
def move_files(src_folder, dest_folder):
    if not os.path.exists(src_folder):
        print(f"Source folder not found: {src_folder}")
        return
    if not os.path.exists(dest_folder):
        os.makedirs(dest_folder, exist_ok=True)

    files = os.listdir(src_folder)
    if not files:
        print(f"No files found in {src_folder}")
        return

    print(f"Moving files from {src_folder} to {dest_folder}")
    for file_name in files:
        src_path = os.path.join(src_folder, file_name)
        dest_path = os.path.join(dest_folder, file_name)
        try:
            shutil.move(src_path, dest_path)
        except Exception as e:
            print(f"Error moving file {src_path}: {e}")


# Move training data
move_files(source_train_cat, dest_train_cats)
move_files(source_train_dog, dest_train_dogs)

# Move validation data
move_files(source_val_cat, dest_val_cats)
move_files(source_val_dog, dest_val_dogs)

print("Finished moving files.")

"""**Reasoning**:
The images have been moved to the correct dataset directories. Now I need to re-run the model training script to train the model using the populated dataset and save the `cat_dog_model.h5` file, which was the cause of the previous errors.


"""

import os
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

IMG_SIZE = 100
data = []
labels = []

# Load dataset
for set_type in ["train", "val"]: # Iterate through both train and val directories
    for category in ['cats', 'dogs']:
        folder = os.path.join("dataset", set_type, category) # Correct the path
        label = 0 if category == 'cats' else 1
        if not os.path.exists(folder):
            print(f"Folder not found: {folder}")
            continue

        print(f"Loading images from {folder}")
        image_files = os.listdir(folder)
        if not image_files:
            print(f"No images found in {folder}")

        for img_name in image_files:
            try:
                path = os.path.join(folder, img_name)
                image = Image.open(path).resize((IMG_SIZE, IMG_SIZE)).convert('RGB') # Add .convert('RGB') to handle potential non-RGB images
                image = np.array(image)
                data.append(image)
                labels.append(label)
            except Exception as e: # Catch specific exceptions during image loading
                print(f"Error loading image {path}: {e}")
                pass # Skip the image if there's an error


if not data:
    print("No images were loaded. Please check the dataset directories and ensure they contain images.")
else:
    # Preprocess
    data = np.array(data) / 255.0
    labels = to_categorical(labels, num_classes=2) # Specify num_classes

    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42) # Add random_state for reproducibility

    # Build model (assuming this part is correct based on the original code)
    model = Sequential([
        Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
        MaxPooling2D((2,2)),
        Conv2D(64, (3,3), activation='relu'),
        MaxPooling2D((2,2)),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(2, activation='softmax')
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

    # Save model (assuming this part is correct based on the original code)
    os.makedirs("model", exist_ok=True) # Ensure the model directory exists
    model.save("model/cat_dog_model.h5")

"""**Reasoning**:
The model has been successfully trained and saved as `model/cat_dog_model.h5`. The `utils.py` file was also created. Now, I can attempt to run the Streamlit application again, as the dependency on the model file should be resolved.


"""

import streamlit as st
from PIL import Image
from utils import predict
import matplotlib.pyplot as plt

st.title("🐱🐶 Cat vs Dog Classifier")
uploaded_file = st.file_uploader("Upload a cat or dog image", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Uploaded Image", use_column_width=True)

    if st.button("Classify"):
        label, confidence = predict(image)
        st.markdown(f"### Prediction: *{label}* with confidence {confidence:.2f}")

        # Visual bar
        fig, ax = plt.subplots()
        ax.bar(['Cat', 'Dog'], [confidence, 1-confidence] if label == 'Cat' else [1-confidence, confidence])
        st.pyplot(fig)

"""## Debug streamlit execution in colab

### Subtask:
If the Streamlit app doesn't launch correctly in Colab, provide instructions or code to run it in a compatible way (e.g., using `!streamlit run app.py & npx localtunnel --port 8501`).

**Reasoning**:
Run the Streamlit application and expose it using localtunnel to make it accessible in the Colab environment.
"""

!git push -u origin main

!git config --global user.name "Your Name"
!git config --global user.email "you@example.com"

!git branch -M main
!git push -u origin main

from tensorflow.keras.models import load_model
import numpy as np
from PIL import Image

model = load_model("model/cat_dog_model.h5")

def preprocess_image(image: Image.Image) -> np.ndarray:
    image = image.resize((100, 100))
    image = np.array(image) / 255.0
    return np.expand_dims(image, axis=0)

def predict(image: Image.Image):
    img_array = preprocess_image(image)
    prediction = model.predict(img_array)[0]
    return ("Cat", prediction[0]) if prediction[0] > prediction[1] else ("Dog", prediction[1])

